import numpy as np
import matplotlib.pyplot as plt
from sklearn import svm

# Данные
data_x = [(4.9, 3.3), (5.6, 4.5), (6.4, 4.3), (6.7, 5.7), (6.3, 5.0), (5.2, 3.9), (5.5, 3.7), (5.6, 3.6), (5.5, 3.8), 
           (6.1, 4.7), (7.4, 6.1), (6.0, 5.1), (5.5, 4.4), (5.9, 5.1), (6.5, 5.8), (6.5, 4.6), (6.7, 4.4), (6.3, 5.6), 
           (5.9, 4.8), (6.0, 4.5), (5.6, 4.1), (5.6, 4.9), (4.9, 4.5), (6.2, 4.5), (6.1, 4.7), (6.1, 4.9), (6.2, 5.4), 
           (5.7, 4.2), (6.1, 5.6), (5.8, 4.0), (6.6, 4.6), (5.6, 4.2), (7.2, 6.1), (7.7, 6.7), (5.6, 3.9), (7.7, 6.9), 
           (6.0, 4.0), (6.1, 4.0), (7.6, 6.6), (5.1, 3.0), (6.3, 6.0), (6.7, 5.7), (6.8, 5.9), (6.4, 5.5), (7.0, 4.7), 
           (5.8, 5.1), (5.8, 5.1), (6.4, 5.3), (6.3, 4.9), (6.4, 5.3), (5.7, 3.5), (7.2, 5.8), (6.4, 5.6), (5.7, 4.5), 
           (6.0, 4.5), (7.7, 6.1), (6.2, 4.3), (7.1, 5.9), (7.3, 6.3), (5.0, 3.3), (6.3, 5.1), (5.8, 3.9), (6.4, 4.5), 
           (6.3, 5.6), (6.8, 5.5), (6.9, 5.4), (5.5, 4.0), (5.7, 4.1), (6.5, 5.5), (6.3, 4.7), (5.0, 3.5), (6.7, 5.8), 
           (6.9, 4.9), (7.7, 6.7), (5.8, 4.1), (6.4, 5.6), (6.7, 5.2), (6.7, 4.7), (5.4, 4.5), (6.8, 4.8), (5.7, 4.2), 
           (5.5, 4.0), (6.3, 4.9), (6.5, 5.2), (5.8, 5.1), (6.0, 4.8), (6.2, 4.8), (6.5, 5.1), (7.9, 6.4), (6.7, 5.0), 
           (6.7, 5.6), (6.0, 5.0), (6.1, 4.6), (5.7, 5.0), (7.2, 6.0), (6.3, 4.4), (5.9, 4.2), (6.9, 5.1), (6.6, 4.4), 
           (6.9, 5.7)]
data_y = [-1, -1, -1, 1, 1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 
           1, -1, -1, -1, 1, 1, -1, 1, -1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 
           1, 1, -1, 1, -1, -1, 1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, -1, -1, -1, -1, -1, 1, 1, 
           1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1]

# Обучающая выборка в формате [1, x1, x2]
x_train = np.array([[1] + list(x) for x in data_x])  # входные образы
y_train = np.array(data_y)  # целевые значения (метки классов)

# Обучение модели SVM
model = svm.LinearSVC()
model.fit(x_train, y_train)

# Получение коэффициентов w
w = model.coef_[0]  # коэффициенты w1 и w2
w[0] *= w[2]

# Количество неверных классификаций
predictions = np.sign(x_train @ w)
Q = sum(y_train != predictions)

# Визуализация
plt.figure(figsize=(10, 6))

# Рисуем правильные классификации
plt.scatter(x_train[y_train == 1, 1], x_train[y_train == 1, 2], c='red', label='Класс 1', marker='o')
plt.scatter(x_train[y_train == -1, 1], x_train[y_train == -1, 2], c='blue', label='Класс -1', marker='o')

# Рисуем неверные классификации крестиками
incorrect_indices = np.where(y_train != predictions)[0]
plt.scatter(x_train[incorrect_indices, 1], x_train[incorrect_indices, 2], marker='x', color='black', s=100, label='Неверная классификация')

# Рисуем разделяющую линию
x = np.linspace(4.5, 8.5, 100)  # Удлиняем линию
y = -w[0] / w[2] - w[1] / w[2] * x
plt.plot(x, y, color='green', label='Разделяющая линия')

plt.xlabel('Признак 1')
plt.ylabel('Признак 2')
plt.title('График точек и разделяющей линии SVM')
plt.grid()
plt.legend()
plt.savefig('task4_2_1.png')
plt.show()

# Вывод результатов
print("Коэффициенты w:", w)
print("Количество неверных классификаций Q:", Q)







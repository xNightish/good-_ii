from matplotlib import pyplot as plt
import numpy as np


# экспоненциальная функция потерь
def loss(w, x, y):
    M = np.dot(w, x) * y
    return np.exp(-M)


# производная экспоненциальной функции потерь по вектору w
def df(w, x, y):
    M = np.dot(w, x) * y
    return -np.exp(-M) * x * y


data_x = [(5.8, 1.2), (5.6, 1.5), (6.5, 1.5), (6.1, 1.3), (6.4, 1.3), (7.7, 2.0), (6.0, 1.8), (5.6, 1.3), (6.0, 1.6), (5.8, 1.9), (5.7, 2.0), (6.3, 1.5), (6.2, 1.8), (7.7, 2.3), (5.8, 1.2), (6.3, 1.8), (6.0, 1.0), (6.2, 1.3), (5.7, 1.3), (6.3, 1.9), (6.7, 2.5), (5.5, 1.2), (4.9, 1.0), (6.1, 1.4), (6.0, 1.6), (7.2, 2.5), (7.3, 1.8), (6.6, 1.4), (5.6, 2.0), (5.5, 1.0), (6.4, 2.2), (5.6, 1.3), (6.6, 1.3), (6.9, 2.1), (6.8, 2.1), (5.7, 1.3), (7.0, 1.4), (6.1, 1.4), (6.1, 1.8), (6.7, 1.7), (6.0, 1.5), (6.5, 1.8), (6.4, 1.5), (6.9, 1.5), (5.6, 1.3), (6.7, 1.4), (5.8, 1.9), (6.3, 1.3), (6.7, 2.1), (6.2, 2.3), (6.3, 2.4), (6.7, 1.8), (6.4, 2.3), (6.2, 1.5), (6.1, 1.4), (7.1, 2.1), (5.7, 1.0), (6.8, 1.4), (6.8, 2.3), (5.1, 1.1), (4.9, 1.7), (5.9, 1.8), (7.4, 1.9), (6.5, 2.0), (6.7, 1.5), (6.5, 2.0), (5.8, 1.0), (6.4, 2.1), (7.6, 2.1), (5.8, 2.4), (7.7, 2.2), (6.3, 1.5), (5.0, 1.0), (6.3, 1.6), (7.7, 2.3), (6.4, 1.9), (6.5, 2.2), (5.7, 1.2), (6.9, 2.3), (5.7, 1.3), (6.1, 1.2), (5.4, 1.5), (5.2, 1.4), (6.7, 2.3), (7.9, 2.0), (5.6, 1.1), (7.2, 1.8), (5.5, 1.3), (7.2, 1.6), (6.3, 2.5), (6.3, 1.8), (6.7, 2.4), (5.0, 1.0), (6.4, 1.8), (6.9, 2.3), (5.5, 1.3), (5.5, 1.1), (5.9, 1.5), (6.0, 1.5), (5.9, 1.8)]
data_y = [-1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, 1]

x_train = np.array([[1, x[0], x[1]] for x in data_x])
y_train = np.array(data_y)

n_train = len(x_train)  # размер обучающей выборки
w = [0.0, 0.0, 0.0]  # начальные весовые коэффициенты
nt = np.array([0.5, 0.01, 0.01])  # шаг обучения для каждого параметра w0, w1, w2
lm = 0.01  # значение параметра лямбда для вычисления скользящего экспоненциального среднего
N = 500  # число итераций алгоритма SGD
batch_size = 10 # размер мини-батча (величина K = 10)

Qe = np.mean(loss(w, x_train.T, y_train))  # начальное значение среднего эмпирического риска
np.random.seed(0) # генерация одинаковых последовательностей псевдослучайных чисел

losses = []  # Список для хранения потерь на каждой итерации

for i in range(N):
    k = np.random.randint(0, n_train - batch_size - 1)  # случайный выбор индекса

    # создание минибатча
    x_batch = x_train[k:k + batch_size]
    y_batch = y_train[k:k + batch_size]

    # Обновление Qe
    Qe = (1 - lm) * Qe + lm * np.mean(loss(w, x_batch.T, y_batch))

    # Обновление весов
    gradient = np.mean(df(w, x_batch.T, y_batch), axis=1)
    w -= nt * gradient

    # Сохранение потерь
    losses.append(Qe)
    
Q = np.mean(x_train @ w.T * y_train < 0)

# Создание сетки для визуализации
x_min, x_max = x_train[:, 1].min() - 1, x_train[:, 1].max() + 1
y_min, y_max = x_train[:, 2].min() - 1, x_train[:, 2].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),
                     np.arange(y_min, y_max, 0.1))

# Предсказания для сетки
Z = np.dot(np.c_[np.ones(xx.ravel().shape), xx.ravel(), yy.ravel()], w)
Z = Z.reshape(xx.shape)
Z = np.where(Z > 0, 1, -1)  # Применение порога

# Создание подграфиков 
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))

# График потерь
ax1.set_title('Изменение потерь по итерациям', fontsize=14)
ax1.set_xlabel('Итерация', fontsize=12)
ax1.set_ylabel('Средний риск', fontsize=12)
ax1.plot(losses, label='Средний риск', color='blue')
ax1.legend(loc='upper right')
ax1.grid()

# График данных и разделяющей гиперплоскости
Z = np.dot(np.c_[np.ones(xx.ravel().shape), xx.ravel(), yy.ravel()], w)
Z = Z.reshape(xx.shape)

# Используем contour для отображения линии
contour = ax2.contour(xx, yy, Z, levels=[0], colors='green', linewidths=2, linestyles='--')  # Пунктирная линия
scatter = ax2.scatter(x_train[:, 1], x_train[:, 2], c=y_train, edgecolors='k', marker='o', cmap='coolwarm')
ax2.set_title('Данные и классификация', fontsize=14)
ax2.set_xlabel('Признак 1', fontsize=12)
ax2.set_ylabel('Признак 2', fontsize=12)

ax2.set_xlim(4.5, 8) 
ax2.set_ylim(0.7, 2.7) 

# Добавление легенды на второй график
handles, labels = scatter.legend_elements()
ax2.legend(handles, ['Класс -1', 'Класс 1'], loc='upper right')

ax2.grid()

# Показать график
plt.tight_layout()
# plt.savefig('task4_9_2.png')
plt.show()



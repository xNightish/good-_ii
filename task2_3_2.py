import numpy as np
import matplotlib.pyplot as plt

# Экспоненциальная функция потерь
def loss(w, x, y):
    M = np.dot(w, x) * y
    return np.exp(-M)

# Градиент экспоненциальной функции потерь
def df(w, x, y):
    M = np.dot(w, x) * y
    return -np.exp(-M) * (x * y)

data_x = [(5.8, 1.2), (5.6, 1.5), (6.5, 1.5), (6.1, 1.3), (6.4, 1.3), (7.7, 2.0), (6.0, 1.8), (5.6, 1.3), (6.0, 1.6), (5.8, 1.9), (5.7, 2.0), (6.3, 1.5), (6.2, 1.8), (7.7, 2.3), (5.8, 1.2), (6.3, 1.8), (6.0, 1.0), (6.2, 1.3), (5.7, 1.3), (6.3, 1.9), (6.7, 2.5), (5.5, 1.2), (4.9, 1.0), (6.1, 1.4), (6.0, 1.6), (7.2, 2.5), (7.3, 1.8), (6.6, 1.4), (5.6, 2.0), (5.5, 1.0), (6.4, 2.2), (5.6, 1.3), (6.6, 1.3), (6.9, 2.1), (6.8, 2.1), (5.7, 1.3), (7.0, 1.4), (6.1, 1.4), (6.1, 1.8), (6.7, 1.7), (6.0, 1.5), (6.5, 1.8), (6.4, 1.5), (6.9, 1.5), (5.6, 1.3), (6.7, 1.4), (5.8, 1.9), (6.3, 1.3), (6.7, 2.1), (6.2, 2.3), (6.3, 2.4), (6.7, 1.8), (6.4, 2.3), (6.2, 1.5), (6.1, 1.4), (7.1, 2.1), (5.7, 1.0), (6.8, 1.4), (6.8, 2.3), (5.1, 1.1), (4.9, 1.7), (5.9, 1.8), (7.4, 1.9), (6.5, 2.0), (6.7, 1.5), (6.5, 2.0), (5.8, 1.0), (6.4, 2.1), (7.6, 2.1), (5.8, 2.4), (7.7, 2.2), (6.3, 1.5), (5.0, 1.0), (6.3, 1.6), (7.7, 2.3), (6.4, 1.9), (6.5, 2.2), (5.7, 1.2), (6.9, 2.3), (5.7, 1.3), (6.1, 1.2), (5.4, 1.5), (5.2, 1.4), (6.7, 2.3), (7.9, 2.0), (5.6, 1.1), (7.2, 1.8), (5.5, 1.3), (7.2, 1.6), (6.3, 2.5), (6.3, 1.8), (6.7, 2.4), (5.0, 1.0), (6.4, 1.8), (6.9, 2.3), (5.5, 1.3), (5.5, 1.1), (5.9, 1.5), (6.0, 1.5), (5.9, 1.8)]
data_y = [-1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, 1]

x_train = np.array([[1] + list(x) for x in data_x])
y_train = np.array(data_y)
data_x = np.array(data_x)

n_train = len(x_train)
w = np.zeros(3) # Случайная инициализация
nt = np.array([0.5, 0.01, 0.01])
lm = 0.01
N = 500
batch_size = 10

Qe = np.mean([loss(w, x, y) for x, y in zip(x_train, y_train)])
np.random.seed(0)

for i in range(N):
    k = np.random.randint(0, n_train - batch_size - 1)
    
    # создание минибатча
    batch_x = x_train[k:k + batch_size]
    batch_y = y_train[k:k + batch_size]
    
    # Обновление Qe
    Qe = (1 - lm) * Qe + lm * np.mean([loss(w, x, y) for x, y in zip(batch_x, batch_y)])
    
    # Обновление весов
    gradient = np.mean([df(w, x, y) for x, y in zip(batch_x, batch_y)], axis=0)
    w -= nt * gradient

# Финальная оценка
Q = np.mean(x_train @ w.T * y_train < 0)


print(w)
print(Q)
print(Qe)

# изобразить график точек и линию разделяющую модель
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 10))

x = np.array([4.8, 7.8])
y = -w[0] / w[2] - w[1] / w[2] * x
plt.scatter(x_train[:, 1], x_train[:, 2], c=y_train)

# отобразить разделяющую линию
plt.plot(x, y, color='red')


plt.show()

